{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Classification - Twitter Sentiment Analysis (1.0 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use twitter_training.csv to build a model to determine “if a Tweet content is Positive / Neutral/ Negative or Irrelevant”, then use twitter_validation.csv to test this model.\n",
    "Read more information here:\n",
    "https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-U0BRSSO:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classification-twitter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b73919fa60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('classification-twitter').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import (\n",
    "    Tokenizer,\n",
    "    StopWordsRemover,\n",
    "    RegexTokenizer,\n",
    "    CountVectorizer,\n",
    "    IDF,\n",
    "    StringIndexer,\n",
    "    VectorAssembler\n",
    ")\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "twitter_train = spark.read.csv('twitter_training.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------+--------------------+\n",
      "|Tweet ID|     entity|sentiment|       Tweet content|\n",
      "+--------+-----------+---------+--------------------+\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|I am coming to th...|\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|im coming on bord...|\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "+--------+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| sentiment|count|\n",
      "+----------+-----+\n",
      "|Irrelevant|12990|\n",
      "|  Positive|20832|\n",
      "|   Neutral|18318|\n",
      "|  Negative|22542|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_train.groupby('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74682"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweet ID: integer (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- Tweet content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------+--------------------+\n",
      "|Tweet ID|     entity|sentiment|       Tweet content|\n",
      "+--------+-----------+---------+--------------------+\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|I am coming to th...|\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "|    2401|Borderlands| Positive|im coming on bord...|\n",
      "|    2401|Borderlands| Positive|im getting on bor...|\n",
      "+--------+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Tweet ID=2401, entity='Borderlands', sentiment='Positive', Tweet content='im getting on borderlands and i will murder you all ,')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = twitter_train.select(\"sentiment\", \"entity\", \"Tweet content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "sentiment      0\n",
       "entity         0\n",
       "Tweet content  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Kiểm tra dữ liệu NaN, null\n",
    "data_train.select([count(when(isnan(c), c)).alias(c) for c in data_train.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "sentiment        0\n",
       "entity           0\n",
       "Tweet content  686"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.select([count(when(col(c).isNull(), c)).alias(c) for c in data_train.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.dropna(subset='Tweet content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "sentiment      0\n",
       "entity         0\n",
       "Tweet content  0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.select([count(when(col(c).isNull(), c)).alias(c) for c in data_train.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Kiểm tra dữ liệu trùng. \n",
    "num_rows = data_train.count()\n",
    "num_dist_rows = data_train.distinct().count()\n",
    "dup_rows = num_rows - num_dist_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73996"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "70912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(num_rows, num_dist_rows, dup_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3084"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Có dữ liệu trùng\n",
    "dup_rows = num_rows - num_dist_rows\n",
    "dup_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa dữ liệu trùng\n",
    "data_train = data_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70912"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.withColumn('length', length(data_train['Tweet content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.filter(data_train['length'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+------+\n",
      "|sentiment|     entity|       Tweet content|length|\n",
      "+---------+-----------+--------------------+------+\n",
      "| Negative|Borderlands|@ Borderlands how...|    82|\n",
      "| Positive|Borderlands|I am here... With...|   203|\n",
      "| Positive|Borderlands|We've been over p...|   208|\n",
      "| Positive|Borderlands|Actually. I think...|   124|\n",
      "| Negative|Borderlands|That cricket was ...|   147|\n",
      "+---------+-----------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "| sentiment|       avg(length)|\n",
      "+----------+------------------+\n",
      "|Irrelevant|110.82921926509609|\n",
      "|  Positive| 98.03137475688402|\n",
      "|   Neutral| 118.8148339950515|\n",
      "|  Negative|112.01758048056406|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not Clear Difference\n",
    "data_train.groupby('sentiment').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| sentiment|count|\n",
      "+----------+-----+\n",
      "|Irrelevant|12437|\n",
      "|  Positive|19538|\n",
      "|   Neutral|17379|\n",
      "|  Negative|21558|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.groupby('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.select('entity').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              entity|count|\n",
      "+--------------------+-----+\n",
      "|       Cyberpunk2077| 2144|\n",
      "|         Borderlands| 2191|\n",
      "|       Xbox(Xseries)| 2164|\n",
      "|   PlayStation5(PS5)| 2177|\n",
      "|                FIFA| 2224|\n",
      "|           Overwatch| 2208|\n",
      "|             Verizon| 2301|\n",
      "|        WorldOfCraft| 2244|\n",
      "|      AssassinsCreed| 2141|\n",
      "|PlayerUnknownsBat...| 2112|\n",
      "|               CS-GO| 2169|\n",
      "|         Battlefield| 2236|\n",
      "| GrandTheftAuto(GTA)| 2201|\n",
      "|           HomeDepot| 2198|\n",
      "|               NBA2K| 2290|\n",
      "|              Google| 2179|\n",
      "|               Dota2| 2217|\n",
      "|RedDeadRedemption...| 2123|\n",
      "|CallOfDutyBlackop...| 2231|\n",
      "|     LeagueOfLegends| 2228|\n",
      "|           Microsoft| 2277|\n",
      "|           MaddenNFL| 2293|\n",
      "|            Fortnite| 2162|\n",
      "|TomClancysRainbowSix| 2287|\n",
      "|              Nvidia| 2174|\n",
      "|              Amazon| 2207|\n",
      "|         Hearthstone| 2201|\n",
      "|          CallOfDuty| 2304|\n",
      "|TomClancysGhostRecon| 2261|\n",
      "|     johnson&johnson| 2244|\n",
      "|         ApexLegends| 2246|\n",
      "|            Facebook| 2278|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.groupby('entity').count().show(32, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "twitter_test = spark.read.csv('twitter_validation.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1509"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweet ID: string (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- Tweet content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+--------------------+\n",
      "|Tweet ID|   entity| sentiment|       Tweet content|\n",
      "+--------+---------+----------+--------------------+\n",
      "|    3364| Facebook|Irrelevant|I mentioned on Fa...|\n",
      "|     352|   Amazon|   Neutral|BBC News - Amazon...|\n",
      "|    8312|Microsoft|  Negative|@Microsoft Why do...|\n",
      "|    4371|    CS-GO|  Negative|CSGO matchmaking ...|\n",
      "|    4433|   Google|   Neutral|Now the President...|\n",
      "+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Tweet ID='3364', entity='Facebook', sentiment='Irrelevant', Tweet content='I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom’s great auntie as ‘Hayley can’t get out of bed’ and told to his grandma, who now thinks I’m a lazy, terrible person 🤣')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = twitter_test.select(\"sentiment\", \"entity\", \"Tweet content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "sentiment      0\n",
       "entity         0\n",
       "Tweet content  0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Kiểm tra dữ liệu NaN, null\n",
    "data_val.select([count(when(isnan(c), c)).alias(c) for c in data_val.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "sentiment      494\n",
       "entity         466\n",
       "Tweet content  509"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.select([count(when(col(c).isNull(), c)).alias(c) for c in data_val.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = data_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "sentiment      0\n",
       "entity         0\n",
       "Tweet content  0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.select([count(when(col(c).isNull(), c)).alias(c) for c in data_val.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Kiểm tra dữ liệu trùng. \n",
    "num_rows = data_val.count()\n",
    "num_dist_rows = data_val.distinct().count()\n",
    "dup_rows = num_rows - num_dist_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(num_rows, num_dist_rows, dup_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| sentiment|count|\n",
      "+----------+-----+\n",
      "|Irrelevant|  172|\n",
      "|   Neutral|  285|\n",
      "|  Positive|  277|\n",
      "|  Negative|  266|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_val.groupby('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BsTextExtractor(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(BsTextExtractor, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "\n",
    "        def f(s):\n",
    "            cleaned_post = BeautifulSoup(s).text\n",
    "            return cleaned_post\n",
    "\n",
    "        t = StringType()\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_to_num = StringIndexer(inputCol='sentiment',outputCol='sentimentIndex') #1\n",
    "entity_to_num = StringIndexer(inputCol='entity',outputCol='entityIndex') #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extractor = BsTextExtractor(inputCol=\"Tweet content\", outputCol=\"cleaned_Tweet\") #3\n",
    "tokenizer = RegexTokenizer(inputCol=\"cleaned_Tweet\", outputCol=\"token_text\", pattern=\"\\\\W\") #4\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens') #5\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec') #6\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\") #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols=['tf_idf','entityIndex'],\n",
    "                           outputCol='features') # 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "We'll use Naive Bayes, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use defaults\n",
    "nb = NaiveBayes(labelCol='sentimentIndex',featuresCol='features', smoothing=1.0, modelType=\"multinomial\")\n",
    "lg = LogisticRegression(labelCol='sentimentIndex',featuresCol='features', maxIter=20, regParam=0.3, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[sentiment_to_num,\n",
    "                                  entity_to_num,\n",
    "                                  text_extractor,\n",
    "                                  tokenizer,\n",
    "                                  stopremove,\n",
    "                                  count_vec,\n",
    "                                  idf,\n",
    "                                  clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_data = cleaner.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+------+--------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|sentiment|     entity|       Tweet content|length|sentimentIndex|entityIndex|       cleaned_Tweet|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+---------+-----------+--------------------+------+--------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Negative|Borderlands|@ Borderlands how...|    82|           0.0|       21.0|@ Borderlands how...|[borderlands, how...|[borderlands, fil...|(30756,[63,187,28...|(30756,[63,187,28...|(30757,[63,187,28...|\n",
      "| Positive|Borderlands|I am here... With...|   203|           1.0|       21.0|I am here... With...|[i, am, here, wit...|[samsung, full, h...|(30756,[5,10,63,6...|(30756,[5,10,63,6...|(30757,[5,10,63,6...|\n",
      "| Positive|Borderlands|We've been over p...|   208|           1.0|       21.0|We've been over p...|[we, ve, been, ov...|[ve, playing, lot...|(30756,[0,4,13,22...|(30756,[0,4,13,22...|(30757,[0,4,13,22...|\n",
      "| Positive|Borderlands|Actually. I think...|   124|           1.0|       21.0|Actually. I think...|[actually, i, thi...|[actually, think,...|(30756,[13,15,63,...|(30756,[13,15,63,...|(30757,[13,15,63,...|\n",
      "| Negative|Borderlands|That cricket was ...|   147|           0.0|       21.0|That cricket was ...|[that, cricket, w...|[cricket, worst, ...|(30756,[3,34,63,7...|(30756,[3,34,63,7...|(30757,[3,34,63,7...|\n",
      "+---------+-----------+--------------------+------+--------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_clean_data.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_data = cleaner.transform(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+--------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| sentiment|   entity|       Tweet content|sentimentIndex|entityIndex|       cleaned_Tweet|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+----------+---------+--------------------+--------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Irrelevant| Facebook|I mentioned on Fa...|           3.0|        5.0|I mentioned on Fa...|[i, mentioned, on...|[mentioned, faceb...|(30756,[2,5,24,30...|(30756,[2,5,24,30...|(30757,[2,5,24,30...|\n",
      "|   Neutral|   Amazon|BBC News - Amazon...|           2.0|       17.0|BBC News - Amazon...|[bbc, news, amazo...|[bbc, news, amazo...|(30756,[3,22,29,1...|(30756,[3,22,29,1...|(30757,[3,22,29,1...|\n",
      "|  Negative|Microsoft|@Microsoft Why do...|           0.0|        6.0|@Microsoft Why do...|[microsoft, why, ...|[microsoft, pay, ...|(30756,[39,287,70...|(30756,[39,287,70...|(30757,[39,287,70...|\n",
      "|  Negative|    CS-GO|CSGO matchmaking ...|           0.0|       25.0|CSGO matchmaking ...|[csgo, matchmakin...|[csgo, matchmakin...|(30756,[1,135,285...|(30756,[1,135,285...|(30757,[1,135,285...|\n",
      "|   Neutral|   Google|Now the President...|           2.0|       22.0|Now the President...|[now, the, presid...|[president, slapp...|(30756,[0,12,36,7...|(30756,[0,12,36,7...|(30757,[0,12,36,7...|\n",
      "+----------+---------+--------------------+--------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_clean_data.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_clean_data.select(\"features\",'sentimentIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70912"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models (its three models, so it might take some time)\n",
    "nb_model = nb.fit(train_data)\n",
    "lg_model = lg.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    " use twitter_validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_clean_data.select(\"features\",'sentimentIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- sentimentIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.transform(test_data)\n",
    "lg_predictions = lg_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"sentimentIndex\", \n",
    "                                                  predictionCol=\"prediction\", \n",
    "                                                  metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_acc = acc_evaluator.evaluate(nb_predictions)\n",
    "lg_acc = acc_evaluator.evaluate(lg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - confusions matrix:\n",
      "+--------------+----------+-----+\n",
      "|sentimentIndex|prediction|count|\n",
      "+--------------+----------+-----+\n",
      "|           0.0|       0.0|  226|\n",
      "|           0.0|       1.0|   30|\n",
      "|           0.0|       2.0|    1|\n",
      "|           0.0|       3.0|    9|\n",
      "|           1.0|       0.0|   14|\n",
      "|           1.0|       1.0|  252|\n",
      "|           1.0|       2.0|    5|\n",
      "|           1.0|       3.0|    6|\n",
      "|           2.0|       0.0|   20|\n",
      "|           2.0|       1.0|   42|\n",
      "|           2.0|       2.0|  210|\n",
      "|           2.0|       3.0|   13|\n",
      "|           3.0|       0.0|    8|\n",
      "|           3.0|       1.0|   14|\n",
      "|           3.0|       2.0|    3|\n",
      "|           3.0|       3.0|  147|\n",
      "+--------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes - confusions matrix:\")\n",
    "nb_cm = nb_predictions.groupBy('sentimentIndex', 'prediction').count().orderBy('sentimentIndex', 'prediction')\n",
    "nb_cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - confusions matrix:\n",
      "+--------------+----------+-----+\n",
      "|sentimentIndex|prediction|count|\n",
      "+--------------+----------+-----+\n",
      "|           0.0|       0.0|  248|\n",
      "|           0.0|       1.0|   16|\n",
      "|           0.0|       2.0|    2|\n",
      "|           1.0|       0.0|   14|\n",
      "|           1.0|       1.0|  260|\n",
      "|           1.0|       2.0|    2|\n",
      "|           1.0|       3.0|    1|\n",
      "|           2.0|       0.0|   25|\n",
      "|           2.0|       1.0|   34|\n",
      "|           2.0|       2.0|  223|\n",
      "|           2.0|       3.0|    3|\n",
      "|           3.0|       0.0|   15|\n",
      "|           3.0|       1.0|   25|\n",
      "|           3.0|       2.0|    3|\n",
      "|           3.0|       3.0|  129|\n",
      "+--------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression - confusions matrix:\")\n",
    "lg_cm = lg_predictions.groupBy('sentimentIndex', 'prediction').count().orderBy('sentimentIndex', 'prediction')\n",
    "lg_cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on twitter_validation.csv:\n",
      "--------------------------------------------------------------------------------\n",
      "Naive Bayes - accuracy: 83.50%\n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression - accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on twitter_validation.csv:\")\n",
    "print('-'*80)\n",
    "print('Naive Bayes - accuracy: {0:2.2f}%'.format(nb_acc*100))\n",
    "print('-'*80)\n",
    "print('Logistic Regression - accuracy: {0:2.2f}%'.format(lg_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So sánh đánh giá giữa Naive Bayes và Logistic Regression\n",
    "\n",
    "| Tiêu chí         | Naive Bayes  | Logistic Regression |\n",
    "|------------------|--------------|---------------------|\n",
    "| **Accuracy**     | 83.50%       | 86.00%              |\n",
    "| **Confusion Matrix** | | |\n",
    "| 0.0 - 0.0        | 226          | 248                 |\n",
    "| 0.0 - 1.0        | 30           | 16                  |\n",
    "| 0.0 - 2.0        | 1            | 2                   |\n",
    "| 0.0 - 3.0        | 9            | 0                 |\n",
    "| 1.0 - 0.0        | 14           | 14                  |\n",
    "| 1.0 - 1.0        | 252          | 260                 |\n",
    "| 1.0 - 2.0        | 5            | 2                   |\n",
    "| 1.0 - 3.0        | 6            | 1                   |\n",
    "| 2.0 - 0.0        | 20           | 25                  |\n",
    "| 2.0 - 1.0        | 42           | 34                  |\n",
    "| 2.0 - 2.0        | 210          | 223                 |\n",
    "| 2.0 - 3.0        | 13           | 3                   |\n",
    "| 3.0 - 0.0        | 8            | 15                  |\n",
    "| 3.0 - 1.0        | 14           | 25                  |\n",
    "| 3.0 - 2.0        | 3            | 3                   |\n",
    "| 3.0 - 3.0        | 147          | 129                 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dựa trên bảng so sánh trên, Logistic Regression có accuracy cao hơn và ít lỗi hơn trong confusion matrix so với Naive Bayes. Do đó, Logistic Regression là  thuật toán phù hợp hơn cho bộ dữ liệu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "nb.save(\"NB_Tweeter_ Sentiment_model\")\n",
    "lg.save(\"Lg_Tweeter_ Sentiment_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
